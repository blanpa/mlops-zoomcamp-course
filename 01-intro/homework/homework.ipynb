{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Homework\n",
    "\n",
    "The goal of this homework is to train a simple model for predicting the duration of a ride - similar to what we did in this module.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q1. Downloading the data\n",
    "\n",
    "We'll use [the same NYC taxi dataset](https://www1.nyc.gov/site/tlc/about/tlc-trip-record-data.page),\n",
    "but instead of \"**Green** Taxi Trip Records\", we'll use \"**Yellow** Taxi Trip Records\".\n",
    "\n",
    "Download the data for January and February 2023.\n",
    "\n",
    "Read the data for January. How many columns are there?\n",
    "\n",
    "* 16\n",
    "* 17\n",
    "* 18\n",
    "* 19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Den Pfad zum 'helper'-Verzeichnis hinzufügen\n",
    "helper_dir = os.path.join(os.path.dirname(os.path.abspath(\"__file__\")), 'helper')\n",
    "if helper_dir not in sys.path:\n",
    "    sys.path.append(helper_dir)\n",
    "\n",
    "# Jetzt können wir die Funktion importieren\n",
    "from download_tlc_helper import download_tlc_data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading from: https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-01.parquet\n",
      "Datei heruntergeladen und gespeichert unter: tlc_data/yellow_tripdata/yellow_tripdata_2023-01.parquet\n",
      "Downloading from: https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-02.parquet\n",
      "Datei heruntergeladen und gespeichert unter: tlc_data/yellow_tripdata/yellow_tripdata_2023-02.parquet\n"
     ]
    }
   ],
   "source": [
    "# Beispielverwendung der Helper-Funktion\n",
    "record_type = \"yellow_tripdata\"\n",
    "year = 2023\n",
    "months = [1, 2]\n",
    "\n",
    "download_tlc_data(record_type, year, months)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns Count of Dataset:  19\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_2023_01 = pd.read_parquet(\"tlc_data/yellow_tripdata/yellow_tripdata_2023-01.parquet\")\n",
    "print(\"Columns Count of Dataset: \", len(df_2023_01.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q2. Computing duration\n",
    "\n",
    "Now let's compute the `duration` variable. It should contain the duration of a ride in minutes. \n",
    "\n",
    "What's the standard deviation of the trips duration in January?\n",
    "\n",
    "* 32.59\n",
    "* 42.59\n",
    "* 52.59\n",
    "* 62.59"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['VendorID', 'tpep_pickup_datetime', 'tpep_dropoff_datetime',\n",
       "       'passenger_count', 'trip_distance', 'RatecodeID', 'store_and_fwd_flag',\n",
       "       'PULocationID', 'DOLocationID', 'payment_type', 'fare_amount', 'extra',\n",
       "       'mta_tax', 'tip_amount', 'tolls_amount', 'improvement_surcharge',\n",
       "       'total_amount', 'congestion_surcharge', 'airport_fee'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2023_01.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standard deviation of the trips duration in January:  42.59\n"
     ]
    }
   ],
   "source": [
    "df_2023_01[\"duration\"] = df_2023_01.tpep_dropoff_datetime - df_2023_01.tpep_pickup_datetime\n",
    "df_2023_01.duration = df_2023_01.duration.apply(lambda td: td.total_seconds() / 60)\n",
    "df_2023_01.duration.std()\n",
    "print(\"Standard deviation of the trips duration in January: \" , df_2023_01.duration.std().round(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q3. Dropping outliers\n",
    "\n",
    "Next, we need to check the distribution of the `duration` variable. There are some outliers. Let's remove them and keep only the records where the duration was between 1 and 60 minutes (inclusive).\n",
    "\n",
    "What fraction of the records left after you dropped the outliers?\n",
    "\n",
    "* 90%\n",
    "* 92%\n",
    "* 95%\n",
    "* 98%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fraction of the records left after you dropped the outliers:  0.9812202822125979\n"
     ]
    }
   ],
   "source": [
    "df_2023_01_wo = df_2023_01[(df_2023_01.duration >= 1) & (df_2023_01.duration <=60)] # remove outliers\n",
    "\n",
    "# What fraction of the records left after you dropped the outliers?\n",
    "fraction = len(df_2023_01_wo) / len(df_2023_01)\n",
    "print(\"Fraction of the records left after you dropped the outliers: \", fraction)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q4. One-hot encoding\n",
    "\n",
    "Let's apply one-hot encoding to the pickup and dropoff location IDs. We'll use only these two features for our model. \n",
    "\n",
    "* Turn the dataframe into a list of dictionaries (remember to re-cast the ids to strings - otherwise it will \n",
    "  label encode them)\n",
    "* Fit a dictionary vectorizer \n",
    "* Get a feature matrix from it\n",
    "\n",
    "What's the dimensionality of this matrix (number of columns)?\n",
    "\n",
    "* 2\n",
    "* 155\n",
    "* 345\n",
    "* 515\n",
    "* 715"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "515"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction import DictVectorizer\n",
    "\n",
    "# Turn the dataframe into a list of dictionaries\n",
    "train_dicts = df_2023_01_wo[['PULocationID', 'DOLocationID']].astype(str).to_dict(orient='records')\n",
    "\n",
    "# Fit a dictionary vectorizer\n",
    "dv = DictVectorizer()\n",
    "dv.fit(train_dicts)\n",
    "\n",
    "# Get the feature matrix\n",
    "X_train = dv.transform(train_dicts)\n",
    "\n",
    "# Get the dimensionality of the matrix\n",
    "num_columns = X_train.shape[1]\n",
    "num_columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q5. Training a model\n",
    "\n",
    "Now let's use the feature matrix from the previous step to train a model. \n",
    "\n",
    "* Train a plain linear regression model with default parameters \n",
    "* Calculate the RMSE of the model on the training data\n",
    "\n",
    "What's the RMSE on train?\n",
    "\n",
    "* 3.64\n",
    "* 7.64\n",
    "* 11.64\n",
    "* 16.64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/la/miniconda3/envs/mlobs/lib/python3.10/site-packages/sklearn/metrics/_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "7.649261822035489"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "target = 'duration'\n",
    "y_train = df_2023_01_wo[target].values\n",
    "\n",
    "# Train the linear regression model\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict the target variable\n",
    "y_train_pred = model.predict(X_train)\n",
    "\n",
    "# Calculate the RMSE\n",
    "rmse = mean_squared_error(y_train, y_train_pred, squared=False)\n",
    "rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q6. Evaluating the model\n",
    "\n",
    "Now let's apply this model to the validation dataset (February 2023). \n",
    "\n",
    "What's the RMSE on validation?\n",
    "\n",
    "* 3.81\n",
    "* 7.81\n",
    "* 11.81\n",
    "* 16.81\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2023_02 = pd.read_parquet(\"tlc_data/yellow_tripdata/yellow_tripdata_2023-02.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2023_02[\"duration\"] = df_2023_02.tpep_dropoff_datetime - df_2023_02.tpep_pickup_datetime\n",
    "df_2023_02.duration = df_2023_02.duration.apply(lambda td: td.total_seconds() / 60)\n",
    "df_2023_02_wo = df_2023_02[(df_2023_02.duration >= 1) & (df_2023_02.duration <=60)]\n",
    "\n",
    "\n",
    "train_dicts_2 = df_2023_02_wo[['PULocationID', 'DOLocationID']].astype(str).to_dict(orient='records')\n",
    "\n",
    "# Fit a dictionary vectorizer\n",
    "dv2 = DictVectorizer()\n",
    "dv2.fit(train_dicts_2)\n",
    "\n",
    "# Get the feature matrix\n",
    "X_test = dv.transform(train_dicts_2)\n",
    "\n",
    "y_test_pred = model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/la/miniconda3/envs/mlobs/lib/python3.10/site-packages/sklearn/metrics/_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "7.811821332387183"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test = df_2023_02_wo[target].values\n",
    "\n",
    "rmse_test = mean_squared_error(y_test, y_test_pred, squared=False)\n",
    "rmse_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlobs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
